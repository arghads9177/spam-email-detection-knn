{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ba99d1-473c-464e-918a-3c7b4275e68f",
   "metadata": {},
   "source": [
    "# Spam Email Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project focuses on detecting spam emails using a dataset containing information from 5,172 randomly selected email files. The goal is to build a classification model that can accurately distinguish between spam and not-spam emails based on the content of the emails.\n",
    "\n",
    "## Source\n",
    "\n",
    "This dataset is available on Kaggele in the following link:\n",
    "\n",
    "> https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "The dataset is provided in a CSV file with the following characteristics:\n",
    "\n",
    "- **Rows**: 5,172 rows, each representing an individual email.\n",
    "- **Columns**: 3,002 columns in total.\n",
    "  - **First Column**: Indicates the email name. The names have been anonymized with numbers to protect privacy.\n",
    "  - **Last Column**: Contains the labels for classification:\n",
    "    - `1` for spam emails.\n",
    "    - `0` for not-spam emails.\n",
    "  - **Remaining 3,000 Columns**: These columns represent the 3,000 most common words across all emails, excluding non-alphabetical characters. Each cell in these columns contains the count of the respective word in the corresponding email.\n",
    "\n",
    "This compact representation allows for efficient processing and analysis of email data without needing to work with separate text files.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "1. **Model Training**: Train the model with training dataset so that it can identify whether an email is spam or not.\n",
    "2. **Model Evaluation**: Evaluate the performance of the trained model using the evaluation metrics such as accuracy, precision, recall and F1 score.\n",
    "3. **Model Optimization**: Optimeze the performance of the model with cross validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613253de-a478-4207-8b7a-0b0f6a29392f",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8c13ed2-1d4f-4eed-beb8-d7c6ef1c599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model and evaluation metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d63585-3290-4f54-9de8-3904353c581e",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74dc8e77-505e-4ac1-81a6-b05df85767bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "model_path = \"../models\"\n",
    "# csv_path = os.path.join(data_path, \"emails_fr.csv\")\n",
    "csv_path = os.path.join(data_path, \"emails_or.csv\")\n",
    "# csv_path = os.path.join(data_path, \"emails_pca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0199e-0231-465b-b893-5daa27c41681",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60f66408-423e-449d-aea8-74fc7c8f5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "380df897-bfba-4570-944e-f060d840588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  valued  \\\n",
       "0    0   0    1    0    0   0    2    0    0   0  ...         0    0       0   \n",
       "1    8  13   24    6    6   2  102    1   27  18  ...         0    0       0   \n",
       "2    0   0    1    0    0   0    8    0    0   4  ...         0    0       0   \n",
       "3    0   5   22    0    5   1   51    2   10   1  ...         0    0       0   \n",
       "4    7   6   17    1    5   2   57    0    9   3  ...         0    0       0   \n",
       "\n",
       "   lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0    0               0         0         0   0    0           0  \n",
       "1    0               0         0         0   1    0           0  \n",
       "2    0               0         0         0   0    0           0  \n",
       "3    0               0         0         0   0    0           0  \n",
       "4    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8727f-c799-4ec4-9680-ffd341d932e3",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec6f93e3-b194-4c04-8ec1-a58ab67f6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input and output features\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09e2a98a-317f-45d6-abb3-65580f7ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd671a02-3725-40e6-b7cb-1b3aedcd37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the the data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4cc9b-ef3b-4e51-8750-647752f3a5a8",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21f41630-a471-4008-99d1-0758a6557fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_evaluate(model, y_train):\n",
    "    # Train the model with training set\n",
    "    model.fit(X_train_s, y_train)\n",
    "\n",
    "    # Predict on training and testing data\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_test_pred = model.predict(X_test_s)\n",
    "\n",
    "    # print evaluation metrics for taring and testing\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_train_pred):.3f}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_train_pred):.3f}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_train_pred):.3f}\")\n",
    "    print(f\"F1: {f1_score(y_train, y_train_pred):.3f}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54d90dda-010d-41ed-babe-15e24e3bdb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING\n",
      "============================================================\n",
      "Accuracy: 0.897\n",
      "Precision: 0.742\n",
      "Recall: 0.972\n",
      "F1: 0.841\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING\n",
      "============================================================\n",
      "Accuracy: 0.849\n",
      "Precision: 0.642\n",
      "Recall: 0.972\n",
      "F1: 0.773\n"
     ]
    }
   ],
   "source": [
    "# Train the KNN Classifier with training data and evaluate performance with 4 metrics\n",
    "knn = KNeighborsClassifier()\n",
    "train_evaluate(knn, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256098b8-d5bb-4fbc-9f9f-53b762644315",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "The evaluation metrics for the KNN classifier on the Spam Email classification task show good overall performance, especially in terms of generalization to the testing data. Here’s a detailed analysis:\n",
    "\n",
    "#### Training Metrics (High scores):\n",
    "\n",
    "- **Accuracy (0.90)**: The model correctly classifies **89.7%** of the training data. This indicates that the model has learned the patterns in the training data well.\n",
    "- **Precision (0.74)**: The precision of **74.2%** means that of all the emails classified as spam, **74.2%** were actually spam. The model is making a noticeable number of false positive predictions, where legitimate emails are incorrectly classified as spam.\n",
    "- **Recall (0.97)**: Recall is very high at **97.2%**, indicating that the model is correctly identifying almost all actual spam emails in the training data.\n",
    "- **F1 Score(0.84)**: The F1 score, which balances precision and recall, is **84.1%**, indicating good overall performance. The lower precision is pulling down the F1 score a bit, suggesting the need to reduce false positives.\n",
    "- \n",
    "#### Testing Metrics (Slightly lower):\n",
    "\n",
    "- **Accuracy (0.85)**: The model correctly classifies **84.9%** of the testing data, a good performance. This suggests the model generalizes well to unseen data. But the difference from the training accuracy is showing slightly overfitting.\n",
    "- **Precision (0.64)**: The precision on the test set is **64.2%**, which is lower than on the training set. This suggests the model is making more false positive predictions on the test data (i.e., classifying legitimate emails as spam).\n",
    "- **Recall (0.97)**: The recall on the test set is **97.2%**, meaning the model correctly identifies **97.2%** of the actual actual non-spam emails.\n",
    "- **F1 Score (0.77)**: The F1 score for the test data is **77.3%**, which is lower than the training F1 score (**84.1%**). This drop indicates that the model is struggling with precision on the test set, leading to a trade-off between precision and recall.\n",
    "\n",
    "#### Analysis of Performance:\n",
    "\n",
    "- **High Recall, Low Precision:** Both on the training and testing data, the model has very high recall (**97.2%**) but relatively low precision, especially on the test set (**64.2%**). This means that while the model is excellent at catching most spam emails (low false negatives), it struggles with distinguishing between spam and legitimate emails, leading to more false positives (legitimate emails classified as spam). **In spam detection**, high recall is typically prioritized because missing spam emails can be more harmful than wrongly classifying legitimate emails as spam. However, low precision can result in user frustration, as important emails might be wrongly classified as spam and go unnoticed.\n",
    "- **Generalization:** The model's performance on the test set is slightly worse than on the training set, which is expected. The drop in precision (**from 74.2% to 64.2%**) suggests that the model is overfitting to the training data when it comes to distinguishing between legitimate and spam emails. The generalization to unseen data could be improved by addressing overfitting through techniques such as hyperparameter tuning or using regularization.\n",
    "- **F1 Score:** The F1 score balances precision and recall, and its drop from training (**0.841**) to testing (**0.773**) reflects the precision issue. Since the F1 score is lower on the test set, it indicates that the model’s ability to balance catching spam emails while minimizing false positives deteriorates slightly when applied to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba276824-63c2-4995-84b6-f4c4e12350eb",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "\n",
    "- Try to find the optimal model using hyperparameter tuning and corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "befbec9f-d9dc-41a5-b715-566274d3f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429128119838767\n"
     ]
    }
   ],
   "source": [
    "# KFold Cross validation\n",
    "kf = KFold(n_splits= 5)\n",
    "\n",
    "knn_cv = KNeighborsClassifier()\n",
    "\n",
    "# Cross validation\n",
    "cvs = cross_val_score(knn_cv, X, y, cv= kf)\n",
    "print(cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54e542f2-7683-4ad9-989e-546a23f8fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "def tune_hyperparameter(model, param_dict):\n",
    "    # Difine tuner\n",
    "    gvcv = GridSearchCV(estimator= model,\n",
    "                   param_grid= param_dict,\n",
    "                   cv= 5,\n",
    "                   verbose= 1, scoring= \"precision\")\n",
    "    # Train the tuner\n",
    "    gvcv.fit(X, y)\n",
    "\n",
    "    # Get Best parameters and print best score\n",
    "    best_params = gvcv.best_params_\n",
    "    print(f\"Best Score: {gvcv.best_score_}\")\n",
    "\n",
    "    return best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4dbc824-ce38-43e7-8ee9-c13181d5634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Score: 0.7175680862904007\n",
      "Best Parameter set: {'n_neighbors': 13, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Define Hyperparameter\n",
    "param_dict = {\n",
    "    \"n_neighbors\": [5, 7, 9, 11, 13],\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "cv_model = KNeighborsClassifier()\n",
    "best_params = tune_hyperparameter(cv_model, param_dict)\n",
    "print(f\"Best Parameter set: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a63114e-82b4-408e-be7a-78d65bd846ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING\n",
      "============================================================\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1: 1.000\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING\n",
      "============================================================\n",
      "Accuracy: 0.795\n",
      "Precision: 0.565\n",
      "Recall: 0.992\n",
      "F1: 0.720\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate with best parameters\n",
    "model = KNeighborsClassifier(**best_params)\n",
    "train_evaluate(model, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613ccd9-53f1-44fa-a5c5-1b7be581ed77",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "After hyperparameter tuning for the Spam Email classification with the KNN classifier, I obtained the following results:\n",
    "\n",
    "#### Training Metrics (Perfect scores):\n",
    "\n",
    "- **Accuracy (1.0)**: The model achieves perfect accuracy on the training set, classifying all emails (both spam and legitimate) correctly.\n",
    "- **Precision (1.0)**: The precision is also perfect, meaning that every email classified as spam was indeed spam.\n",
    "- **Recall (1.0)**: The model detects **100%** of the actual spam emails in the training data (no false negatives).\n",
    "- **F1 Score(1.0)**:  The F1 score is a perfect **1.0**, reflecting the model's flawless performance on the training data.\n",
    "  \n",
    "#### Testing Metrics (Slightly lower):\n",
    "\n",
    "- **Accuracy (0.80)**: On the test set, the model's accuracy drops to **79.5%**, indicating that the model does not generalize as well to unseen data.\n",
    "- **Precision (0.57)**: Precision is quite low (**56.5%**), meaning that only **56.5%** of the emails classified as spam on the test set are actually spam. This suggests a high number of false positives (legitimate emails classified as spam).\n",
    "- **Recall (0.99)**: Recall remains very high (**99.2%**), indicating that the model successfully identifies almost all spam emails in the test set, with very few false negatives.\n",
    "- **F1 Score (0.72)**: The F1 score is **0.72**, reflecting the imbalance between precision and recall, but it shows reasonable overall performance, albeit not as good as on the training data.\n",
    "\n",
    "#### Analysis of Performance:\n",
    "\n",
    "- **High Recall, Low Precision:** The recall on the test set remains very high (**99.2%**), meaning the model is still very good at catching almost all spam emails. However, the precision (**56.5%**) is quite low, meaning the model is classifying a significant number of legitimate emails as spam (false positives). Low precision could be problematic in a real-world spam detection scenario, where users might miss important legitimate emails if they are wrongly classified as spam.\n",
    "- **Overfitting:** The model achieves perfect performance on the training set, which is a strong indication of overfitting. KNN might be memorizing the training data, especially if a small **k** value was selected during hyperparameter tuning. This results in excellent performance on training data but poor generalization to unseen data (as indicated by the drop in accuracy and precision on the test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1263f-f6e0-427a-8d3b-53dfbd2fd5a6",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a08fd556-df2c-4db3-8223-27d9de6035fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_r, y_train_r = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5a28719-4122-457f-a829-c60ca37fec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling the resampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train_r)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a68c6bb-609b-43fa-b54f-793c7e465d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING\n",
      "============================================================\n",
      "Accuracy: 1.000\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1: 1.000\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING\n",
      "============================================================\n",
      "Accuracy: 0.663\n",
      "Precision: 0.440\n",
      "Recall: 1.000\n",
      "F1: 0.611\n"
     ]
    }
   ],
   "source": [
    "# Try KNN Classifier\n",
    "knn_r = KNeighborsClassifier(**best_params)\n",
    "train_evaluate(knn_r, y_train_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4499503-1ed8-4d53-8b7d-3eae50121b75",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After applying oversampling on the training data, the evaluation metrics are as follows:\n",
    "\n",
    "#### Training Metrics (Perfect scores):\n",
    "\n",
    "- **Accuracy (1.0)**: The model achieves perfect accuracy on the training set, classifying all emails (both spam and legitimate) correctly.\n",
    "- **Precision (1.0)**: The precision is also perfect, meaning that every email classified as spam was indeed spam.\n",
    "- **Recall (1.0)**: The model detects **100%** of the actual spam emails in the training data (no false negatives).\n",
    "- **F1 Score(1.0)**:  The F1 score is a perfect **1.0**, reflecting the model's flawless performance on the training data.\n",
    "\n",
    "#### Testing Metrics:\n",
    "\n",
    "- **Accuracy (0.66)**: The accuracy on the test set is quite low (**66.3%**), showing that the model is struggling to generalize well to unseen data.\n",
    "- **Precision (0.44)**: Precision has dropped significantly to **44%**, meaning that less than half of the emails classified as spam are actually spam. This suggests a high number of false positives (legitimate emails misclassified as spam).\n",
    "- **Recall (1.0)**: Recall is perfect, meaning that the model identifies all actual spam emails in the test set. This implies that the model is very aggressive in classifying emails as spam, hence it catches every spam email but at the cost of many false positives.\n",
    "- **F1 Score (0.61)**: The F1 score is **0.611**, which reflects the imbalance between precision and recall. Despite high recall, the low precision drags down the overall performance.\n",
    "\n",
    "#### Analysis of Performance:\n",
    "\n",
    "- **Overfitting due to Oversampling:** The model achieves perfect scores on the oversampled training data, but this is a strong indication of overfitting. Oversampling replicates the minority class (spam emails) in the training set, which can make the model too sensitive to identifying spam, especially when paired with a KNN classifier. As a result, the model memorizes the training data and cannot generalize well to new, unseen data.\n",
    "- **Evaluate Different Models:** KNN may not be the best model for this problem, especially given its tendency to memorize the data rather than generalize. Consider evaluating more advanced classifiers such as **Random Forest, XGBoost, or even SVM**. These models often perform better with imbalanced datasets and have built-in mechanisms to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95dbfb-5fb8-4ea7-94c6-85d5dd3de7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
